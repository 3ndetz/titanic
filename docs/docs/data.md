# Data

Всё про данные в проекте.

## Содержание

- [Data](#data)
  - [Содержание](#содержание)
  - [Текущие данные в проекте](#текущие-данные-в-проекте)
    - [Структура папок](#структура-папок)
    - [Текущие данные](#текущие-данные)
  - [Загрузка новых данных](#загрузка-новых-данных)
  - [Версионирование данных](#версионирование-данных)

## Текущие данные в проекте

### Структура папок

Данные хранятся в папке `data/` в корне проекта.

### Текущие данные

Изначальные сырые данные скачаны вручную из [Kaggle](https://www.kaggle.com/competitions/titanic/data) и помещены в `data/raw/`.

> Более красивым способом будет автоматизация через Kaggle и скачивание командой

Далее с данными была проведена работа, см. раздел ниже.

## Загрузка новых данных

Чтобы добавить новые данные в проект, нужно:

1. Положить новые сырые данные `.csv` в папку `data/raw/`.
2. Подготовить схемы данных в формате, совместимом с pandera schema и создать соответствующие yaml-файлы:
   1. `data/raw/<new_dataset>_metadata.yaml` - для сырых данных
   2. `data/processed/<new_dataset>_metadata.yaml` - для обработанных данных
   3. Создать pydantic-модель для валидации строк новых данных в `titanic/schema/dataset_schema.py` для комфортной работе в коде.
3. При необходимости изменить обработку новых данных в `titanic/dataset.py`.
4. Запустить команду `dvc repro process_data`, чтобы обработать новые данные и сохранить их в `data/processed/`.
5. Зафиксировать изменения в git, указав название коммита и эксперимента, и сделать dvc push.

## Версионирование данных

Данные версионируются с помощью DVC, подключенному к приложению Google Drive. Для доступа к этому диску сообщите разработчику gmail-почту, и тогда сможете пройти oauth при `dvc pull`.

Соответственно, `dvc pull` подтянет все данные из удалённого хранилища.
